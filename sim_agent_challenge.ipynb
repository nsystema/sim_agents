{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'!conda install -c conda-forge openexr-python -y\\n!pip install waymo-open-dataset-tf-2-11-0==1.5.2  --no-cache-dir \\n!pip install --upgrade google-cloud-storage'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"!conda install -c conda-forge openexr-python -y\n",
        "!pip install waymo-open-dataset-tf-2-11-0==1.5.2  --no-cache-dir \n",
        "!pip install --upgrade google-cloud-storage\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_G1K_QmTl5vQ",
        "outputId": "198789a1-d9e4-47d3-e463-ca4fcfb7a641"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-26 15:29:09.530099: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-26 15:29:13.087618: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2023-05-26 15:29:13.087657: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-05-26 15:29:23.048083: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-05-26 15:29:23.048313: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-05-26 15:29:23.048331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "\n",
        "from waymo_open_dataset.wdl_limited.sim_agents_metrics import metric_features\n",
        "from waymo_open_dataset.wdl_limited.sim_agents_metrics import metrics\n",
        "\n",
        "from waymo_open_dataset.protos import scenario_pb2\n",
        "from waymo_open_dataset.protos import sim_agents_metrics_pb2\n",
        "from waymo_open_dataset.protos import sim_agents_submission_pb2\n",
        "from google.protobuf import text_format\n",
        "\n",
        "from waymo_open_dataset.utils.sim_agents import submission_specs\n",
        "from waymo_open_dataset.utils.sim_agents import test_utils as sim_agents_test_utils\n",
        "from waymo_open_dataset.utils.sim_agents import visualizations\n",
        "from waymo_open_dataset.utils import trajectory_utils\n",
        "\n",
        "# Set matplotlib to jshtml so animations work with colab.\n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "from download import download_from_gcs\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x_oklHSal5vR"
      },
      "source": [
        "# Downloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9ObwY0Rl5vS",
        "outputId": "5dadc54c-23a1-40b4-f214-34c3d1338676"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'waymo-od-1-2-0-fb3a3a0b6e6e.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Download samples\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m download_from_gcs(\u001b[39m'\u001b[39;49m\u001b[39muncompressed/scenario/validation/validation.tfrecord-00000-of-00150\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m download_from_gcs(\u001b[39m'\u001b[39m\u001b[39muncompressed/scenario/training/training.tfrecord-00000-of-01000\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m download_from_gcs(\u001b[39m'\u001b[39m\u001b[39muncompressed/scenario/testing/testing.tfrecord-00000-of-00150\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m/workspaces/sim_agents/download.py:21\u001b[0m, in \u001b[0;36mdownload_from_gcs\u001b[0;34m(gcs_path)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m already exists in \u001b[39m\u001b[39m{\u001b[39;00mlocal_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[39m# Set up the storage client with api key: AIzaSyAtD_clSdxcEp4YXa2gWtFuhi6xSEEb_K8\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     client \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39;49mClient\u001b[39m.\u001b[39;49mfrom_service_account_json(\u001b[39m'\u001b[39;49m\u001b[39mwaymo-od-1-2-0-fb3a3a0b6e6e.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     22\u001b[0m     \u001b[39m# Get a reference to the bucket and object\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     bucket \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mbucket(\u001b[39m'\u001b[39m\u001b[39mwaymo_open_dataset_motion_v_1_2_0\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m/workspaces/sim_agents/.conda/lib/python3.10/site-packages/google/cloud/client/__init__.py:106\u001b[0m, in \u001b[0;36m_ClientFactoryMixin.from_service_account_json\u001b[0;34m(cls, json_credentials_path, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_service_account_json\u001b[39m(\u001b[39mcls\u001b[39m, json_credentials_path, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     86\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Factory to retrieve JSON credentials while creating client.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[1;32m     88\u001b[0m \u001b[39m    :type json_credentials_path: str\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m             and the credentials created by the factory.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     \u001b[39mwith\u001b[39;00m io\u001b[39m.\u001b[39;49mopen(json_credentials_path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m json_fi:\n\u001b[1;32m    107\u001b[0m         credentials_info \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(json_fi)\n\u001b[1;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_service_account_info(credentials_info, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'waymo-od-1-2-0-fb3a3a0b6e6e.json'"
          ]
        }
      ],
      "source": [
        "# Download samples\n",
        "download_from_gcs('uncompressed/scenario/validation/validation.tfrecord-00000-of-00150')\n",
        "download_from_gcs('uncompressed/scenario/training/training.tfrecord-00000-of-01000')\n",
        "download_from_gcs('uncompressed/scenario/testing/testing.tfrecord-00000-of-00150')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qMTFcOA0l5vT"
      },
      "source": [
        "# Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Kv9EWLDql5vT"
      },
      "outputs": [],
      "source": [
        "DATASET_FOLDER = '/content/drive/MyDrive/Colab Notebooks/waymo_open_dataset_'\n",
        "\n",
        "TRAIN_FILES = os.path.join(DATASET_FOLDER, 'training.tfrecord*')\n",
        "VALIDATION_FILES = os.path.join(DATASET_FOLDER, 'validation.tfrecord*')\n",
        "TEST_FILES = os.path.join(DATASET_FOLDER, 'testing.tfrecord*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iCHtvnAll5vT"
      },
      "outputs": [],
      "source": [
        "def Prepare_train_dataset():\n",
        "    filenames = tf.io.matching_files(TRAIN_FILES)\n",
        "    dataset = tf.data.TFRecordDataset(filenames)\n",
        "    return dataset\n",
        "\n",
        "def Prepare_validation_dataset():\n",
        "    filenames = tf.io.matching_files(VALIDATION_FILES)\n",
        "    dataset = tf.data.TFRecordDataset(filenames)\n",
        "    return dataset\n",
        "\n",
        "def Prepare_test_dataset():\n",
        "    filenames = tf.io.matching_files(TEST_FILES)\n",
        "    dataset = tf.data.TFRecordDataset(filenames)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8beDyV8yl5vT",
        "outputId": "9d4ba5f7-686a-40e8-d544-9c30965e659b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking type: <class 'waymo_open_dataset.protos.scenario_pb2.Scenario'>\n",
            "Loaded scenario with ID: 4b60f9400a30ceaf\n"
          ]
        }
      ],
      "source": [
        "# scenario exemple\n",
        "dataset_iterator = Prepare_train_dataset().as_numpy_iterator()\n",
        "bytes_example = next(dataset_iterator)\n",
        "scenario = scenario_pb2.Scenario.FromString(bytes_example)\n",
        "print(f'Checking type: {type(scenario)}')\n",
        "print(f'Loaded scenario with ID: {scenario.scenario_id}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZavp8Qtl5vT",
        "outputId": "0ba5a5fc-37ea-4ec2-952c-300bf1b73990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "List of all the fields of the scenario object: ['ByteSize', 'Clear', 'ClearExtension', 'ClearField', 'CopyFrom', 'DESCRIPTOR', 'DiscardUnknownFields', 'Extensions', 'FindInitializationErrors', 'FromString', 'HasExtension', 'HasField', 'IsInitialized', 'ListFields', 'MergeFrom', 'MergeFromString', 'ParseFromString', 'RegisterExtension', 'SerializePartialToString', 'SerializeToString', 'SetInParent', 'UnknownFields', 'WhichOneof', '_CheckCalledFromGeneratedFile', '_SetListener', '__class__', '__deepcopy__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__unicode__', '_extensions_by_name', '_extensions_by_number', 'compressed_frame_laser_data', 'current_time_index', 'dynamic_map_states', 'map_features', 'objects_of_interest', 'scenario_id', 'sdc_track_index', 'timestamps_seconds', 'tracks', 'tracks_to_predict']\n"
          ]
        }
      ],
      "source": [
        "# get the list of all the possible functions of the scenario object\n",
        "print(f'List of all the fields of the scenario object: {[f for f in dir(scenario) if not callable(f)]}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
