{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'!conda install -c conda-forge openexr-python -y\\n!pip install waymo-open-dataset-tf-2-11-0==1.5.2  --no-cache-dir \\n!pip install --upgrade google-cloud-storage'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"!conda install -c conda-forge openexr-python -y\n",
        "!pip install waymo-open-dataset-tf-2-11-0==1.5.2  --no-cache-dir \n",
        "!pip install --upgrade google-cloud-storage\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_G1K_QmTl5vQ",
        "outputId": "198789a1-d9e4-47d3-e463-ca4fcfb7a641"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "\n",
        "from waymo_open_dataset.wdl_limited.sim_agents_metrics import metric_features\n",
        "from waymo_open_dataset.wdl_limited.sim_agents_metrics import metrics\n",
        "\n",
        "from waymo_open_dataset.protos import scenario_pb2\n",
        "from waymo_open_dataset.protos import sim_agents_metrics_pb2\n",
        "from waymo_open_dataset.protos import sim_agents_submission_pb2\n",
        "from google.protobuf import text_format\n",
        "\n",
        "from waymo_open_dataset.utils.sim_agents import submission_specs\n",
        "from waymo_open_dataset.utils.sim_agents import test_utils as sim_agents_test_utils\n",
        "from waymo_open_dataset.utils.sim_agents import visualizations\n",
        "from waymo_open_dataset.utils import trajectory_utils\n",
        "\n",
        "# Set matplotlib to jshtml so animations work with colab.\n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "# deactivating the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from download import download_from_gcs\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x_oklHSal5vR"
      },
      "source": [
        "# Downloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9ObwY0Rl5vS",
        "outputId": "5dadc54c-23a1-40b4-f214-34c3d1338676"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading uncompressed/scenario/validation/validation.tfrecord-00000-of-00150: 261MB [00:09, 29.0MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object downloaded to waymo_open_dataset_/validation.tfrecord-00000-of-00150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading uncompressed/scenario/training/training.tfrecord-00000-of-01000: 428MB [00:16, 27.5MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object downloaded to waymo_open_dataset_/training.tfrecord-00000-of-01000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading uncompressed/scenario/testing/testing.tfrecord-00000-of-00150: 202MB [00:09, 22.2MB/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object downloaded to waymo_open_dataset_/testing.tfrecord-00000-of-00150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Download samples\n",
        "download_from_gcs('uncompressed/scenario/validation/validation.tfrecord-00000-of-00150')\n",
        "download_from_gcs('uncompressed/scenario/training/training.tfrecord-00000-of-01000')\n",
        "download_from_gcs('uncompressed/scenario/testing/testing.tfrecord-00000-of-00150')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qMTFcOA0l5vT"
      },
      "source": [
        "# Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Kv9EWLDql5vT"
      },
      "outputs": [],
      "source": [
        "DATASET_FOLDER = '/content/drive/MyDrive/Colab Notebooks/waymo_open_dataset_'\n",
        "\n",
        "TRAIN_FILES = os.path.join(DATASET_FOLDER, 'training.tfrecord*')\n",
        "VALIDATION_FILES = os.path.join(DATASET_FOLDER, 'validation.tfrecord*')\n",
        "TEST_FILES = os.path.join(DATASET_FOLDER, 'testing.tfrecord*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iCHtvnAll5vT"
      },
      "outputs": [],
      "source": [
        "def Prepare_train_dataset():\n",
        "    filenames = tf.io.matching_files(TRAIN_FILES)\n",
        "    dataset = tf.data.TFRecordDataset(filenames)\n",
        "    return dataset\n",
        "\n",
        "def Prepare_validation_dataset():\n",
        "    filenames = tf.io.matching_files(VALIDATION_FILES)\n",
        "    dataset = tf.data.TFRecordDataset(filenames)\n",
        "    return dataset\n",
        "\n",
        "def Prepare_test_dataset():\n",
        "    filenames = tf.io.matching_files(TEST_FILES)\n",
        "    dataset = tf.data.TFRecordDataset(filenames)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8beDyV8yl5vT",
        "outputId": "9d4ba5f7-686a-40e8-d544-9c30965e659b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-26 16:34:42.100824: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2023-05-26 16:34:42.149856: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2023-05-26 16:34:42.184884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (codespaces-a6b224): /proc/driver/nvidia/version does not exist\n",
            "2023-05-26 16:34:42.649207: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "ename": "StopIteration",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[0;32m/workspaces/sim_agents/.conda/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:787\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 787\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    788\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n",
            "File \u001b[0;32m/workspaces/sim_agents/.conda/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:770\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 770\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    771\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    772\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    773\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    775\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    776\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n",
            "File \u001b[0;32m/workspaces/sim_agents/.conda/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3017\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3016\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3017\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3018\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n",
            "File \u001b[0;32m/workspaces/sim_agents/.conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7214\u001b[0m e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[0;31mOutOfRangeError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} End of sequence [Op:IteratorGetNext]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# scenario exemple\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dataset_iterator \u001b[39m=\u001b[39m Prepare_train_dataset()\u001b[39m.\u001b[39mas_numpy_iterator()\n\u001b[0;32m----> 3\u001b[0m bytes_example \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(dataset_iterator)\n\u001b[1;32m      4\u001b[0m scenario \u001b[39m=\u001b[39m scenario_pb2\u001b[39m.\u001b[39mScenario\u001b[39m.\u001b[39mFromString(bytes_example)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mChecking type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(scenario)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m/workspaces/sim_agents/.conda/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:4770\u001b[0m, in \u001b[0;36m_NumpyIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4767\u001b[0m     numpy\u001b[39m.\u001b[39msetflags(write\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   4768\u001b[0m   \u001b[39mreturn\u001b[39;00m numpy\n\u001b[0;32m-> 4770\u001b[0m \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mmap_structure(to_numpy, \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator))\n",
            "File \u001b[0;32m/workspaces/sim_agents/.conda/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:789\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_internal()\n\u001b[1;32m    788\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[0;32m--> 789\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# scenario exemple\n",
        "dataset_iterator = Prepare_train_dataset().as_numpy_iterator()\n",
        "bytes_example = next(dataset_iterator)\n",
        "scenario = scenario_pb2.Scenario.FromString(bytes_example)\n",
        "print(f'Checking type: {type(scenario)}')\n",
        "print(f'Loaded scenario with ID: {scenario.scenario_id}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZavp8Qtl5vT",
        "outputId": "0ba5a5fc-37ea-4ec2-952c-300bf1b73990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "List of all the fields of the scenario object: ['ByteSize', 'Clear', 'ClearExtension', 'ClearField', 'CopyFrom', 'DESCRIPTOR', 'DiscardUnknownFields', 'Extensions', 'FindInitializationErrors', 'FromString', 'HasExtension', 'HasField', 'IsInitialized', 'ListFields', 'MergeFrom', 'MergeFromString', 'ParseFromString', 'RegisterExtension', 'SerializePartialToString', 'SerializeToString', 'SetInParent', 'UnknownFields', 'WhichOneof', '_CheckCalledFromGeneratedFile', '_SetListener', '__class__', '__deepcopy__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__unicode__', '_extensions_by_name', '_extensions_by_number', 'compressed_frame_laser_data', 'current_time_index', 'dynamic_map_states', 'map_features', 'objects_of_interest', 'scenario_id', 'sdc_track_index', 'timestamps_seconds', 'tracks', 'tracks_to_predict']\n"
          ]
        }
      ],
      "source": [
        "# get the list of all the possible functions of the scenario object\n",
        "print(f'List of all the fields of the scenario object: {[f for f in dir(scenario) if not callable(f)]}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
